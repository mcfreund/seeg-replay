{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# exploring LFP timeseries data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import mne\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import bz2\n",
    "import _pickle\n",
    "from joblib import Parallel, delayed\n",
    "#import matplotlib\n",
    "#import matplotlib.pyplot as plt\n",
    "\n",
    "#%matplotlib qt\n",
    "#%matplotlib inline\n",
    "\n",
    "## constants\n",
    "\n",
    "sfreq = 1024\n",
    "scale = 1e6\n",
    "trigs = {\n",
    "    9: \"trial_start\",\n",
    "    20: \"fix_start\",\n",
    "    22: \"fix_resp\",\n",
    "    72: \"clip_start\",\n",
    "    74: \"clip_stop\",\n",
    "    82: \"clipcue_start\",\n",
    "    84: \"clipcue_stop\",\n",
    "    36: \"loc_start\",\n",
    "    38: \"loc_resp\",\n",
    "    56: \"col_start\",\n",
    "    58: \"col_resp\",\n",
    "    18: \"trial_stop\"\n",
    "}\n",
    "\n",
    "## functions\n",
    "\n",
    "def load_pkl(path):\n",
    "    \"\"\" loads compressed pickle file \"\"\"\n",
    "\n",
    "    with bz2.open(path, 'rb') as f:\n",
    "        neural_data = _pickle.load(f)\n",
    "    return neural_data\n",
    "\n",
    "\n",
    "def load_session(\n",
    "    subject, date, session,\n",
    "    contacts = None,\n",
    "    dir_data = '/oscar/data/brainstorm-ws/seeg_data/Memory Task Data/Epilepsy/Monitoring/'\n",
    "    ):\n",
    "    \"\"\" loads all SEEG data from single session\"\"\"\n",
    "\n",
    "    dir_data_sess = os.path.join(dir_data, date + \"_\" + subject + \"_\" + session)\n",
    "    if contacts is None:\n",
    "        ## list of all in directory:\n",
    "        data_files = [os.path.join(dir_data_sess, file) for file in os.listdir(dir_data_sess) if '.pbz2' in file and \"Events\" not in file]\n",
    "    else:\n",
    "        ## list of only those specified in contacts. if specified, ensures set and order of data matches chinfo.\n",
    "        data_files = [os.path.join(dir_data_sess, date + \"_\" + subject + \"_\" + c + \".pbz2\") for c in contacts]\n",
    "        ## now drop any data files/contacts that do not exist (as a file)\n",
    "        data_files = [file for file in data_files if os.path.exists(file)]\n",
    "        contacts =  [contact for contact, file in zip(contacts, data_files) if os.path.exists(file)]\n",
    "        \n",
    "    data = [load_pkl(fn) for fn in data_files]\n",
    "\n",
    "    return data, contacts\n",
    "\n",
    "\n",
    "def load_events(\n",
    "    subject, date, session,\n",
    "    dir_data = '/oscar/data/brainstorm-ws/seeg_data/Memory Task Data/Epilepsy/Monitoring/'\n",
    "    ):\n",
    "    \"\"\" loads all SEEG data from single session\"\"\"\n",
    "\n",
    "    dir_data_sess = os.path.join(dir_data, date + \"_\" + subject + \"_\" + session)\n",
    "    events_file = [os.path.join(dir_data_sess, file) for file in os.listdir(dir_data_sess) if 'Events.pbz2' in file]\n",
    "    if len(events_file) > 1:\n",
    "        raise Exception(\"Multiple event files found. \" + events_file)\n",
    "    events_data = load_pkl(events_file[0])\n",
    "    \n",
    "    return events_data\n",
    "\n",
    "\n",
    "def load_chinfo(\n",
    "    subject, date, session,\n",
    "    dir_chinfo = '/oscar/data/brainstorm-ws/seeg_data/Memory Task Data/Imaging/Epilepsy'\n",
    "    ):\n",
    "    \"\"\" wrangles channel / anatomical info from excel files. optionally sorts row order to match channel order in a signal_labels object.\"\"\"\n",
    "\n",
    "    chinfo = pd.read_excel(os.path.join(dir_chinfo, subject, \"parsed.xlsx\"))\n",
    "    ## create new columns in chinfo that separate electrode and site/contact info:\n",
    "    ## NB: sites nested in electrodes\n",
    "    chinfo[[\"electrode\", \"site\"]] = chinfo[\"contact\"].str.extract('([a-zA-Z-]+)(\\d+)', expand = True)\n",
    "    ## create col that will become ch_name in raw:\n",
    "    chinfo[\"ch_name\"] = chinfo[\"Anatomical Label\"] + \"_wm-\" + chinfo[\"White Matter\"].astype(\"string\")\n",
    "    chinfo = chinfo.sort_values(\"index\")\n",
    "    \n",
    "    return chinfo\n",
    "\n",
    "\n",
    "def construct_raw(\n",
    "    subject, date, session, \n",
    "    trigs,\n",
    "    dir_data = '/oscar/data/brainstorm-ws/seeg_data/Memory Task Data/Epilepsy/Monitoring/',\n",
    "    dir_chinfo = '/oscar/data/brainstorm-ws/seeg_data/Memory Task Data/Imaging/Epilepsy',\n",
    "    sfreq = 1024,\n",
    "    scale = 1e6\n",
    "    ):\n",
    "    \"\"\" constructs raw data object for a given session \"\"\"\n",
    "\n",
    "    ## load data and events files:\n",
    "    events_data = load_events(subject, date, session, dir_data)\n",
    "    chinfo = load_chinfo(subject, date, session, dir_chinfo)\n",
    "    contacts = chinfo[\"contact\"]\n",
    "    data, contacts = load_session(subject, date, session, contacts, dir_data)  ## intersection of contacts and data_files taken\n",
    "    chinfo = chinfo[chinfo[\"contact\"].isin(contacts)]\n",
    "    ## TODO: mark chinfo and contacts that are missing.\n",
    "    events = np.stack(events_data[\"signal\"])\n",
    "    signals = np.stack([d[\"signal\"] for d in data]) / scale # ideally, in V\n",
    "\n",
    "    ## create stimulus channel for events:\n",
    "    n_times = signals.shape[1]\n",
    "    stim_data = np.zeros((1, n_times))\n",
    "    for samp_i in range(n_times):\n",
    "        is_evt = events[:, 1] == samp_i\n",
    "        if np.sum(is_evt) == 1:\n",
    "            evt_i = np.where(is_evt)[0]\n",
    "            stim_data[0, samp_i] = events[evt_i, 0][0]\n",
    "        elif np.sum(is_evt) > 1:\n",
    "            raise Exception(\"multiple events during same sample ... issue?\")\n",
    "    \n",
    "    ## metadata:\n",
    "    n_channels = len(data) + 1 ## SEEG plus one stimulus channel\n",
    "    ch_names = chinfo[\"ch_name\"].tolist() + [\"stimuli\"]\n",
    "    ch_types = [\"seeg\"] * (n_channels - 1) + [\"stim\"]\n",
    "    info = mne.create_info(ch_names, ch_types = ch_types, sfreq = sfreq)\n",
    "\n",
    "    ## construct raw (ensure signals and stim data order match ch_types/names)\n",
    "    raw = mne.io.RawArray(np.concatenate([signals, stim_data]), info)\n",
    "    \n",
    "    ## events -> annotations\n",
    "    events = mne.find_events(raw)\n",
    "    annot_from_events = mne.annotations_from_events(events, event_desc = trigs, sfreq = raw.info['sfreq'])\n",
    "    raw.set_annotations(annot_from_events)\n",
    "\n",
    "    return raw, chinfo\n",
    "\n",
    "\n",
    "\n",
    "def _cluster_contacts(signal_list):\n",
    "    \"\"\" return electrode-contact hierarchy \"\"\"\n",
    "\n",
    "    signal_dict = {}\n",
    "\n",
    "    for sig in signal_list:\n",
    "        sig_grps = re.search('([A-Z|0-9]{1,}[-| ])?([A-Z]{1,})([0-9]{1,})', sig, re.IGNORECASE)\n",
    "        if sig_grps:\n",
    "            n_grps = len(sig_grps.groups())\n",
    "            electrode = ''.join(filter(None,[sig_grps.group(i) for i in range(1, n_grps)]))\n",
    "            num = sig_grps.group(n_grps)\n",
    "            if electrode in signal_dict.keys():\n",
    "                assert int(num) not in signal_dict[electrode]\n",
    "                signal_dict[electrode].append(int(num))\n",
    "            else:\n",
    "                signal_dict[electrode] = [int(num)]\n",
    "\n",
    "    return signal_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## build raw object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          date  subject session\n",
      "0   2020-11-12  e0010GP      00\n",
      "1   2020-11-13  e0010GP      01\n",
      "2   2020-11-17  e0010GP      02\n",
      "3   2020-11-18  e0010GP      03\n",
      "4   2021-01-17  e0011XQ      00\n",
      "5   2021-01-18  e0011XQ      01\n",
      "6   2021-01-22  e0011XQ      02\n",
      "7   2021-09-29  e0013LW      00\n",
      "8   2021-10-01  e0013LW      02\n",
      "9   2021-10-02  e0013LW      03\n",
      "10  2021-10-03  e0013LW      04\n",
      "13  2022-11-09  e0015TJ      00\n",
      "14  2022-11-10  e0015TJ      01\n",
      "15  2022-11-11  e0015TJ      02\n",
      "16  2022-11-14  e0015TJ      03\n",
      "17  2022-11-15  e0015TJ      04\n",
      "18  2022-11-20  e0015TJ      05\n",
      "19  2023-02-07  e0016YR      02\n",
      "20  2023-03-01  e0017MC      00\n",
      "21  2023-03-02  e0017MC      01\n"
     ]
    }
   ],
   "source": [
    "dir_data = '/oscar/data/brainstorm-ws/seeg_data/Memory Task Data/Epilepsy/Monitoring/'\n",
    "session_info = []\n",
    "for item in os.listdir(dir_data):\n",
    "    if os.path.isdir(os.path.join(dir_data, item)):\n",
    "        date, subject, session = item.split('_')\n",
    "        session_info.append([date, subject, session])\n",
    "session_info = pd.DataFrame(session_info, columns = ['date', 'subject', 'session'])\n",
    "subjs_with_anat = [\"e0010GP\", \"e0011XQ\", \"e0012ZI\", \"e0013LW\", \"e0015TJ\", \"e0016YR\", \"e0017MC\", \"e0018RI\"]\n",
    "session_info = session_info[session_info[\"subject\"].isin(subjs_with_anat)]\n",
    "print(session_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using qt as 2D backend.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "QStandardPaths: error creating runtime directory '/run/user/140132339' (Permission denied)\n",
      "Qt: Session management error: Authentication Rejected, reason : None of the authentication protocols specified are supported and host-based authentication failed\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<mne_qt_browser._pg_figure.MNEQtBrowser at 0x7fd0e63bf400>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channels marked as bad:\n",
      "none\n"
     ]
    }
   ],
   "source": [
    "raw, chinfo = construct_raw(session_info[0, \"subject\"], session_info[0, \"date\"], session_info[0, \"session\"])\n",
    "print(chinfo)\n",
    "raw.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Triggers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How much \"off-task\" time is there before and after the task in recordings?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Creating RawArray with float64 data, n_channels=92, n_times=1920128\n",
      "    Range : 0 ... 1920127 =      0.000 ...  1875.124 secs\n",
      "Ready.\n",
      "595 events found on stim channel stimuli\n",
      "Event IDs: [ 9 16 18 20 22 27 36 38 56 58 72 74 82 84 94]\n",
      "[46.728515625, 55.38671875]\n",
      "1\n",
      "Creating RawArray with float64 data, n_channels=92, n_times=896128\n",
      "    Range : 0 ... 896127 =      0.000 ...   875.124 secs\n",
      "Ready.\n",
      "341 events found on stim channel stimuli\n",
      "Event IDs: [ 9 18 20 22 27 36 38 56 58 72 74 84]\n",
      "[209.447265625, 44.3017578125]\n",
      "2\n",
      "Creating RawArray with float64 data, n_channels=92, n_times=1532288\n",
      "    Range : 0 ... 1532287 =      0.000 ...  1496.374 secs\n",
      "Ready.\n",
      "581 events found on stim channel stimuli\n",
      "Event IDs: [ 9 18 20 22 36 38 56 58 72 74 82 84]\n",
      "[86.2900390625, 5.2578125]\n",
      "3\n",
      "Creating RawArray with float64 data, n_channels=92, n_times=768128\n",
      "    Range : 0 ... 768127 =      0.000 ...   750.124 secs\n",
      "Ready.\n",
      "Trigger channel stimuli has a non-zero initial value of {initial_value} (consider using initial_event=True to detect this event)\n",
      "Removing orphaned offset at the beginning of the file.\n",
      "330 events found on stim channel stimuli\n",
      "Event IDs: [ 9 18 20 22 36 38 56 58 72 74 84]\n",
      "[199.7021484375, 19.5126953125]\n",
      "4\n",
      "Creating RawArray with float64 data, n_channels=217, n_times=1600064\n",
      "    Range : 0 ... 1600063 =      0.000 ...  1562.562 secs\n",
      "Ready.\n",
      "Trigger channel stimuli has a non-zero initial value of {initial_value} (consider using initial_event=True to detect this event)\n",
      "Removing orphaned offset at the beginning of the file.\n",
      "594 events found on stim channel stimuli\n",
      "Event IDs: [ 9 18 20 22 36 38 56 58 72 74 82 84]\n",
      "[105.64453125, 163.138671875]\n",
      "5\n",
      "Creating RawArray with float64 data, n_channels=217, n_times=1408064\n",
      "    Range : 0 ... 1408063 =      0.000 ...  1375.062 secs\n",
      "Ready.\n",
      "363 events found on stim channel stimuli\n",
      "Event IDs: [ 9 18 20 22 36 38 56 58 72 74 84]\n",
      "[320.4306640625, 221.6025390625]\n",
      "6\n",
      "[0, 0]\n",
      "7\n",
      "Creating RawArray with float64 data, n_channels=50, n_times=3072064\n",
      "    Range : 0 ... 3072063 =      0.000 ...  3000.062 secs\n",
      "Ready.\n",
      "Trigger channel stimuli has a non-zero initial value of {initial_value} (consider using initial_event=True to detect this event)\n",
      "Removing orphaned offset at the beginning of the file.\n",
      "2164 events found on stim channel stimuli\n",
      "Event IDs: [  9  18  20  22  36  38  56  58  72  74  82  84 137 146 148 150 157 164\n",
      " 166 184 186 200 202 210 212]\n",
      "[0, 0]\n",
      "8\n",
      "Creating RawArray with float64 data, n_channels=50, n_times=2764864\n",
      "    Range : 0 ... 2764863 =      0.000 ...  2700.062 secs\n",
      "Ready.\n",
      "Trigger channel stimuli has a non-zero initial value of {initial_value} (consider using initial_event=True to detect this event)\n",
      "Removing orphaned offset at the beginning of the file.\n",
      "1796 events found on stim channel stimuli\n",
      "Event IDs: [  9  18  20  22  36  38  56  58  72  74  82  84 137 146 148 150 164 166\n",
      " 184 186 200 202 210 212]\n",
      "[420.7431640625, 308.4580078125]\n",
      "9\n",
      "Creating RawArray with float64 data, n_channels=50, n_times=1228864\n",
      "    Range : 0 ... 1228863 =      0.000 ...  1200.062 secs\n",
      "Ready.\n",
      "Trigger channel stimuli has a non-zero initial value of {initial_value} (consider using initial_event=True to detect this event)\n",
      "Removing orphaned offset at the beginning of the file.\n",
      "841 events found on stim channel stimuli\n",
      "Event IDs: [  9  18  20  22  36  38  56  58  72  74  84 137 146 148 150 164 166 184\n",
      " 186 200 202 212]\n",
      "[190.8759765625, 79.0537109375]\n",
      "10\n",
      "Creating RawArray with float64 data, n_channels=50, n_times=2124864\n",
      "    Range : 0 ... 2124863 =      0.000 ...  2075.062 secs\n",
      "Ready.\n",
      "Trigger channel stimuli has a non-zero initial value of {initial_value} (consider using initial_event=True to detect this event)\n",
      "Removing orphaned offset at the beginning of the file.\n",
      "1778 events found on stim channel stimuli\n",
      "Event IDs: [  9  18  20  22  36  38  56  58  72  74  82  84 137 146 148 150 164 166\n",
      " 184 186 200 202 210 212 244]\n",
      "[199.9677734375, 79.2646484375]\n",
      "13\n",
      "Creating RawArray with float64 data, n_channels=2, n_times=1344064\n",
      "    Range : 0 ... 1344063 =      0.000 ...  1312.562 secs\n",
      "Ready.\n",
      "Trigger channel stimuli has a non-zero initial value of {initial_value} (consider using initial_event=True to detect this event)\n",
      "Removing orphaned offset at the beginning of the file.\n",
      "698 events found on stim channel stimuli\n",
      "Event IDs: [ 9 18 20 22 36 38 56 58 72 74 82 84]\n",
      "[1.3447265625, 161.9521484375]\n",
      "14\n",
      "[0, 0]\n",
      "15\n",
      "[0, 0]\n",
      "16\n",
      "[0, 0]\n",
      "17\n",
      "[0, 0]\n",
      "18\n"
     ]
    }
   ],
   "source": [
    "prepost = []\n",
    "for i, d in session_info.iterrows():\n",
    "    print(i)\n",
    "    try:\n",
    "        raw, chinfo = construct_raw(date = d[\"date\"], subject = d[\"subject\"], session = d[\"session\"])    \n",
    "        events = mne.find_events(raw)\n",
    "        time_pre = (events[0, 0] - raw.first_samp) / raw.info[\"sfreq\"]\n",
    "        time_post = (raw.last_samp - events[-1, 0]) / raw.info[\"sfreq\"]\n",
    "    except:\n",
    "        time_pre = 0\n",
    "        time_post = 0\n",
    "    \n",
    "    prepost.append([i, time_pre, time_post])\n",
    "    print([time_pre, time_post])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating RawArray with float64 data, n_channels=2, n_times=491520\n",
      "    Range : 0 ... 491519 =      0.000 ...   479.999 secs\n",
      "Ready.\n",
      "Trigger channel stimuli has a non-zero initial value of {initial_value} (consider using initial_event=True to detect this event)\n",
      "Removing orphaned offset at the beginning of the file.\n",
      "341 events found on stim channel stimuli\n",
      "Event IDs: [ 9 18 20 22 36 38 56 58 72 74 82 84]\n",
      "Creating RawArray with float64 data, n_channels=2, n_times=614400\n",
      "    Range : 0 ... 614399 =      0.000 ...   599.999 secs\n",
      "Ready.\n",
      "330 events found on stim channel stimuli\n",
      "Event IDs: [ 9 18 20 22 36 38 56 58 72 74 84]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28mprint\u001b[39m(res)\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\n\u001b[0;32m---> 14\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheck_buffers\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msession_info\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterrows\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/mne/lib/python3.11/site-packages/joblib/parallel.py:1952\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1946\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   1947\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   1948\u001b[0m \u001b[38;5;66;03m# reach the first `yield` statement. This starts the aynchronous\u001b[39;00m\n\u001b[1;32m   1949\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   1950\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1952\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/mne/lib/python3.11/site-packages/joblib/parallel.py:1595\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1592\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m   1594\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1595\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[1;32m   1597\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1598\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1599\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1600\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1601\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/mne/lib/python3.11/site-packages/joblib/parallel.py:1707\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1702\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[1;32m   1703\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[1;32m   1704\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m   1705\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[1;32m   1706\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[0;32m-> 1707\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.01\u001b[39m)\n\u001b[1;32m   1708\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   1710\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[1;32m   1711\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[1;32m   1712\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def check_buffers(i, d):\n",
    "    try:\n",
    "        raw, chinfo = construct_raw(date = d[\"date\"], subject = d[\"subject\"], session = d[\"session\"])    \n",
    "        events = mne.find_events(raw)\n",
    "        time_pre = (events[0, 0] - raw.first_samp) / raw.info[\"sfreq\"]\n",
    "        time_post = (raw.last_samp - events[-1, 0]) / raw.info[\"sfreq\"]\n",
    "    except:\n",
    "        time_pre = 0\n",
    "        time_post = 0\n",
    "    res = [i, time_pre, time_post]\n",
    "    print(res)\n",
    "    return res\n",
    "\n",
    "results = Parallel(n_jobs = 16)(delayed(check_buffers)(i, d) for i, d in session_info.iterrows())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 46.728515625, 55.38671875],\n",
       " [1, 209.447265625, 44.3017578125],\n",
       " [2, 86.2900390625, 5.2578125],\n",
       " [3, 199.7021484375, 19.5126953125],\n",
       " [4, 105.64453125, 163.138671875],\n",
       " [5, 320.4306640625, 221.6025390625],\n",
       " [6, 193.0947265625, 109.1787109375],\n",
       " [7, 0, 0],\n",
       " [8, 420.7431640625, 308.4580078125],\n",
       " [9, 190.8759765625, 79.0537109375],\n",
       " [10, 199.9677734375, 79.2646484375],\n",
       " [13, 1.3447265625, 161.9521484375],\n",
       " [14, 56.0791015625, 289.4033203125],\n",
       " [15, 95.5634765625, 194.724609375],\n",
       " [16, 103.73828125, 168.2216796875],\n",
       " [17, 1.24609375, 121.08203125],\n",
       " [18, 233.9521484375, 71.12890625],\n",
       " [19, 111.8701171875, 214.8564453125],\n",
       " [20, 151.912109375, 168.416015625],\n",
       " [21, 47.7421875, 215.9375]]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  9,  16,  18,  20,  22,  27,  36,  38,  56,  58,  72,  74,  82,\n",
       "        84,  94,  99, 127, 128, 137, 146, 148, 150, 157, 164, 166, 184,\n",
       "       186, 200, 202, 210, 212, 244])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = []\n",
    "for i, d in session_info.iterrows():\n",
    "    events = load_events(\n",
    "        d[\"subject\"],\n",
    "        d[\"date\"],\n",
    "        d[\"session\"]\n",
    "    )\n",
    "    res.append(np.unique(np.stack(events[\"signal\"])[:, 0]))\n",
    "\n",
    "#[len(x) for x in res]\n",
    "np.unique(np.concatenate(res))\n",
    "#res\n",
    "#[x[\"signal\"] for x in events]\n",
    "\n",
    "#chinfo\n",
    "#prepost_df = pd.DataFrame(prepost, columns = ['time_pre', 'time_post'])\n",
    "#prepost.to_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "341 events found on stim channel stimuli\n",
      "Event IDs: [ 9 18 20 22 27 36 38 56 58 72 74 84]\n"
     ]
    }
   ],
   "source": [
    "events_data = load_events(subject, date, session, dir_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<details open>\n",
       "    <summary><strong>General</strong></summary>\n",
       "    <table class=\"table table-hover table-striped table-sm table-responsive small\">\n",
       "        <tr>\n",
       "            <th>Measurement date</th>\n",
       "            \n",
       "            <td>Unknown</td>\n",
       "            \n",
       "        </tr>\n",
       "        <tr>\n",
       "            <th>Experimenter</th>\n",
       "            \n",
       "            <td>Unknown</td>\n",
       "            \n",
       "        </tr>\n",
       "        <tr>\n",
       "            <th>Participant</th>\n",
       "            \n",
       "            <td>Unknown</td>\n",
       "            \n",
       "        </tr>\n",
       "    </table>\n",
       "    </details>\n",
       "    <details open>\n",
       "        <summary><strong>Channels</strong></summary>\n",
       "        <table class=\"table table-hover table-striped table-sm table-responsive small\">\n",
       "            <tr>\n",
       "                <th>Digitized points</th>\n",
       "                \n",
       "                <td>Not available</td>\n",
       "                \n",
       "            </tr>\n",
       "            <tr>\n",
       "                <th>Good channels</th>\n",
       "                <td>91 sEEG, 1 Stimulus</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <th>Bad channels</th>\n",
       "                <td>None</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <th>EOG channels</th>\n",
       "                <td>Not available</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <th>ECG channels</th>\n",
       "                <td>Not available</td>\n",
       "            </tr>\n",
       "        </table>\n",
       "        </details>\n",
       "        <details open>\n",
       "            <summary><strong>Data</strong></summary>\n",
       "            <table class=\"table table-hover table-striped table-sm table-responsive small\">\n",
       "                \n",
       "                <tr>\n",
       "                    <th>Sampling frequency</th>\n",
       "                    <td>1024.00 Hz</td>\n",
       "                </tr>\n",
       "                \n",
       "                \n",
       "                <tr>\n",
       "                    <th>Highpass</th>\n",
       "                    <td>0.00 Hz</td>\n",
       "                </tr>\n",
       "                \n",
       "                \n",
       "                <tr>\n",
       "                    <th>Lowpass</th>\n",
       "                    <td>512.00 Hz</td>\n",
       "                </tr>\n",
       "                \n",
       "                \n",
       "                \n",
       "                \n",
       "                <tr>\n",
       "                    <th>Duration</th>\n",
       "                    <td>00:14:36 (HH:MM:SS)</td>\n",
       "                </tr>\n",
       "                \n",
       "            </table>\n",
       "            </details>"
      ],
      "text/plain": [
       "<RawArray | 92 x 896128 (875.1 s), ~629.1 MB, data loaded>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using qt as 2D backend.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "QStandardPaths: error creating runtime directory '/run/user/140132339' (Permission denied)\n",
      "Qt: Session management error: Authentication Rejected, reason : None of the authentication protocols specified are supported and host-based authentication failed\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<mne_qt_browser._pg_figure.MNEQtBrowser at 0x7f1ad42b7490>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channels marked as bad:\n",
      "none\n"
     ]
    }
   ],
   "source": [
    "raw.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO:\n",
    "- ~add info: site location information (to ch_names?), strings for trigger codes~\n",
    "- ~determine whether more data (post-task) is needed. --> contact chad/ana if so!~\n",
    "- ~distribution of channels / coverage~\n",
    "- missing channels -- rerun coverage with missings factored in.\n",
    "- add trigger keys / text\n",
    "- align to beh data (metadata for epochs)\n",
    "- save raws and chinfo: build tree\n",
    "- rereference\n",
    "- line noise\n",
    "- filter\n",
    "- basic reports for raws, epochs\n",
    "- time-frequency: define bands, hilbert? (check darcy's slides) and decompose; epoched analysis?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mne",
   "language": "python",
   "name": "mne"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
